{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "\n",
    "# Load Moby Dick\n",
    "moby_dick = load_etext(2701, mirror='https://gutenberg.pglaf.org/')\n",
    "moby_dick = strip_headers(moby_dick).strip()\n",
    "\n",
    "sherlock = load_etext(1661, mirror='https://gutenberg.pglaf.org/')\n",
    "sherlock = strip_headers(sherlock).strip()\n",
    "\n",
    "scarlet = load_etext(244, mirror='https://gutenberg.pglaf.org/')\n",
    "scarlet = strip_headers(scarlet).strip()\n",
    "\n",
    "df = pl.LazyFrame(\n",
    "    {\n",
    "        'index': pl.arange(3, eager=True),\n",
    "        'authors': ['Hermann Melville', 'Arthur Conan Doyle', 'Arthur Conan Doyle'],\n",
    "        'books': ['Moby Dick', 'The Adventures of Sherlock Holmes', 'A Study in Scarlet'],\n",
    "        'texts': [moby_dick, sherlock, scarlet],\n",
    "    }\n",
    ")\n",
    "\n",
    "STOPWORDS = {\n",
    "    \"he\", \"her\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"i\", \"me\", \"mine\", \"my\", \"myself\", \n",
    "    \"our\", \"ours\", \"ourselves\", \"she\", \"thee\", \"their\", \"them\", \"themselves\", \"they\", \"thou\", \n",
    "    \"thy\", \"thyself\", \"us\", \"we\", \"ye\", \"you\", \"your\", \"yours\", \"yourself\"\n",
    "}\n",
    "\n",
    "# Tokenise\n",
    "df = df.with_columns(\n",
    "    pl.col('texts')\n",
    "    .str.replace_all(\"[`']\", '')\n",
    "    .str.extract_all('\\w+')\n",
    "    .list.eval(\n",
    "        pl.element().filter(\n",
    "            ~pl.element().is_in(STOPWORDS) | ~pl.element().str.contains('.*\\d+.*')\n",
    "        )\n",
    "    )\n",
    "    .alias('tokens')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m filtered_tokens \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     df\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mfiltered_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/lazyframe/frame.py:2053\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: index"
     ]
    }
   ],
   "source": [
    "row_token_freqs = (\n",
    "    df\n",
    "    .explode('tokens')\n",
    "    .group_by(['index', 'tokens'])\n",
    "    .agg(pl.len().alias('frequency'))\n",
    ")\n",
    "\n",
    "top_k_tokens = (\n",
    "    row_token_freqs\n",
    "    .group_by('tokens')\n",
    "    .agg(pl.sum('frequency').alias('token_freqs'))\n",
    "    .sort('token_freqs', descending=True)\n",
    "    .limit(500)\n",
    "    .select('tokens')\n",
    ")\n",
    "\n",
    "z_scores = (\n",
    "    row_token_freqs\n",
    "    .join(top_k_tokens, on='tokens', how='inner')\n",
    "    .select([\n",
    "        pl.col('*'),\n",
    "        (pl.col('frequency') - pl.mean('frequency').over('tokens')\n",
    "            / pl.std('frequency').over('tokens')).alias('z_score')\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 1.5 1.  2.5 1. ] [0.70710678 0.70710678 0.         2.12132034 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40532/2459724113.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  token_counts = (token_counts - means) / stds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678, -0.70710678,         nan,         nan,         nan],\n",
       "       [-0.70710678,  0.70710678,         nan, -0.70710678,         nan],\n",
       "       [        nan,         nan,         nan,  0.70710678,         nan]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "token_counts = np.array([[2, 1, 1, np.nan, np.nan],\n",
    "                         [1, 2, 1, 1, 1],\n",
    "                         [np.nan, np.nan, np.nan, 4, 1]])\n",
    "\n",
    "means = np.nanmean(token_counts, axis=0)\n",
    "stds = np.nanstd(token_counts, axis=0, ddof=1)\n",
    "\n",
    "print(means, stds)\n",
    "\n",
    "token_counts = (token_counts - means) / stds\n",
    "token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.699673171197595)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0, 1, 4]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "\n",
    "# Load Moby Dick\n",
    "moby_dick = load_etext(2701, mirror='https://gutenberg.pglaf.org/')\n",
    "moby_dick = strip_headers(moby_dick).strip()\n",
    "\n",
    "sherlock = load_etext(1661, mirror='https://gutenberg.pglaf.org/')\n",
    "sherlock = strip_headers(sherlock).strip()\n",
    "\n",
    "scarlet = load_etext(244, mirror='https://gutenberg.pglaf.org/')\n",
    "scarlet = strip_headers(scarlet).strip()\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        'index': pl.arange(3, eager=True),\n",
    "        'authors': ['Hermann Melville', 'Arthur Conan Doyle', 'Arthur Conan Doyle'],\n",
    "        'books': ['Moby Dick', 'The Adventures of Sherlock Holmes', 'A Study in Scarlet'],\n",
    "        'texts': [moby_dick, sherlock, scarlet],\n",
    "    }\n",
    ")\n",
    "\n",
    "STOPWORDS = {\n",
    "    \"he\", \"her\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"i\", \"me\", \"mine\", \"my\", \"myself\", \n",
    "    \"our\", \"ours\", \"ourselves\", \"she\", \"thee\", \"their\", \"them\", \"themselves\", \"they\", \"thou\", \n",
    "    \"thy\", \"thyself\", \"us\", \"we\", \"ye\", \"you\", \"your\", \"yours\", \"yourself\"\n",
    "}\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col('texts')\n",
    "    .str.replace_all(\"[`']\", '')\n",
    "    .str.extract_all('\\w+')\n",
    "    .list.eval(\n",
    "        pl.element().filter(\n",
    "            ~pl.element().is_in(STOPWORDS) | ~pl.element().str.contains('.*\\d+.*')\n",
    "        )\n",
    "    )\n",
    "    .alias('tokens')\n",
    "# Calculate number of tokens in each text\n",
    ")\n",
    "\n",
    "top_token_freqs = (\n",
    "    df.select(\n",
    "        pl.col('tokens')\n",
    "        .explode()\n",
    "        .value_counts(sort=True)\n",
    "    )\n",
    "    .unnest('tokens')\n",
    "    .limit(500)\n",
    ")\n",
    "\n",
    "df = df.explode('tokens')\n",
    "\n",
    "frequency_df = (\n",
    "    df\n",
    "    .filter(\n",
    "        pl.col('tokens').is_in(top_token_freqs.select('tokens'))\n",
    "    )\n",
    "    .group_by(['index', 'tokens'])\n",
    "    .agg(pl.len().alias('frequency'))\n",
    ")\n",
    "\n",
    "unique_tokens = frequency_df.select('tokens').unique().get_column('tokens')\n",
    "\n",
    "pivoted_df = (\n",
    "    frequency_df.pivot(\n",
    "        values='frequency',\n",
    "        index='index',\n",
    "        on='tokens',\n",
    "        aggregate_function='first'\n",
    "    )\n",
    "    .fill_null(0)\n",
    ")\n",
    "\n",
    "# pivoted_df = (\n",
    "#     frequency_df\n",
    "#     .group_by('index')\n",
    "#     .agg([\n",
    "#         pl.when(pl.col('tokens') == token)\n",
    "#         .then(pl.col('frequency'))\n",
    "#         .otherwise(0)\n",
    "#         .sum()\n",
    "#         .alias(token)\n",
    "#         for token in unique_tokens  # Create a column for each unique token\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "\n",
    "result = (\n",
    "    df\n",
    "    .select(['index', 'authors', 'books', 'tokens', 'texts'])\n",
    "    .unique()\n",
    "    .join(pivoted_df, on='index', how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('tokens').dtypes[0] == pl.String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('tokens').dtypes[0] == pl.String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m frequency_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     df\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39magg(pl\u001b[38;5;241m.\u001b[39mlen()\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m pivoted_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     12\u001b[0m     frequency_df\u001b[38;5;241m.\u001b[39mpivot(\n\u001b[1;32m     13\u001b[0m         values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mfill_null(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.explode('tokens')\n",
    "\n",
    "frequency_df = (\n",
    "    df\n",
    "    .filter(\n",
    "        pl.col('tokens').is_in(top_token_freqs.select('tokens'))\n",
    "    )\n",
    "    .group_by(['index', 'tokens'])\n",
    "    .agg(pl.len().alias('frequency'))\n",
    ")\n",
    "pivoted_df = (\n",
    "    frequency_df.pivot(\n",
    "        values='frequency',\n",
    "        index='index',\n",
    "        on='tokens',\n",
    "        aggregate_function='first'\n",
    "    )\n",
    "    .fill_null(0)\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .select(['index', 'authors', 'books', 'tokens', 'texts'])\n",
    "    .unique()\n",
    "    .join(pivoted_df, on='index', how='left')\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'authors', 'books', 'texts', 'tokens']\n"
     ]
    },
    {
     "ename": "InvalidOperationError",
     "evalue": "`std` operation not supported for dtype `str`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperationError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate mean and standard deviation once\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_to_normalize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_to_normalize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform normalization\u001b[39;00m\n\u001b[1;32m     12\u001b[0m normalized \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect([\n\u001b[1;32m     13\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     14\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_to_normalize]\n\u001b[1;32m     18\u001b[0m ])\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/dataframe/frame.py:8981\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   8881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[1;32m   8882\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[1;32m   8883\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8885\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[1;32m   8886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8979\u001b[0m \u001b[38;5;124;03m    └──────────────┘\u001b[39;00m\n\u001b[1;32m   8980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/lazyframe/frame.py:2053\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mInvalidOperationError\u001b[0m: `std` operation not supported for dtype `str`"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = [col for col in df.columns if col not in ['index', 'authors', 'books', 'tokens', ]]\n",
    "\n",
    "print(df.columns)\n",
    "    \n",
    "# Calculate mean and standard deviation once\n",
    "stats = df.select([\n",
    "    pl.col(columns_to_normalize).mean().alias('mean'),\n",
    "    pl.col(columns_to_normalize).std().alias('std')\n",
    "])\n",
    "\n",
    "# Perform normalization\n",
    "normalized = df.select([\n",
    "    pl.col('index'),\n",
    "    pl.col('authors'),\n",
    "    pl.col('books'),\n",
    "    *[((pl.col(col) - pl.col('mean')) / pl.col('std')).fill_nan(0).alias(col)\n",
    "        for col in columns_to_normalize]\n",
    "])\n",
    "\n",
    "normalized.join(stats, how='cross')\n",
    "\n",
    "\n",
    "\n",
    "# (token_counts - token_counts.mean()) / token_counts.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col('tokens')\n",
    "    .list.eval(\n",
    "        pl.element()\n",
    "        .explode()\n",
    "        .value_counts(sort=True)\n",
    "        .struct.rename_fields(('token', 'count'))\n",
    "    )\n",
    "    .alias('token_counts')\n",
    "])\n",
    "\n",
    "# .map_elements(lambda x: pl.fold(\n",
    "#         acc=pl.struct({'temp': 1}),\n",
    "#         function=lambda acc, y: acc.extend({y['token']: y['count']}),\n",
    "#         exprs=x\n",
    "#     ))\n",
    "\n",
    "# .map_rows(lambda x: pl.fold(\n",
    "#     acc=pl.struct(dummy=pl.lit(None)),  # Start with a dummy field\n",
    "#     function=lambda acc, y: acc.struct.extend(pl.struct({y['token']: y['count']})),\n",
    "#     exprs=pl.col('token_counts')\n",
    "# ), return_dtype=pl.Struct([pl.Field('token_counts', pl.Object)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_tokens = (\n",
    "#     df\n",
    "#     .explode('tokens')  # Explode to have one token per row\n",
    "#     .select('tokens')   # Select only the tokens column\n",
    "#     .unique()           # Get unique tokens\n",
    "#     .to_series()        # Convert to Series\n",
    "#     .to_list()          # Convert Series to a list of unique tokens\n",
    "# )\n",
    "\n",
    "# (\n",
    "#     df.explode('tokens')\n",
    "#     .group_by(('authors', 'books', 'tokens'))\n",
    "#     .agg(\n",
    "#         pl.len().alias('frequency')\n",
    "#     )\n",
    "#     .group_by(['authors', 'books'])\n",
    "#     .agg([\n",
    "#             pl.when(pl.col('token') == token)\n",
    "#             .then(pl.col('frequency'))\n",
    "#             .otherwise(None)\n",
    "#             .sum()\n",
    "#             # .over(['authors', 'books'])\n",
    "#             .alias(token)\n",
    "#             for token in unique_tokens  # Create one column for each unique token\n",
    "#     ])\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "StructFieldNotFoundError",
     "evalue": "token\n\nThis error occurred with the following context stack:\n\t[1] 'select' failed\n\t[2] 'select' input failed to resolve\n\t[3] 'unique' input failed to resolve\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStructFieldNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m unique_tokens \u001b[38;5;241m=\u001b[39m exploded\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Prepare pivot expressions\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pivot_exprs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     pl\u001b[38;5;241m.\u001b[39mwhen(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m token)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mthen(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mover([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39malias(token)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43munique_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_column(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply pivot expressions\u001b[39;00m\n\u001b[1;32m     15\u001b[0m pivoted \u001b[38;5;241m=\u001b[39m exploded\u001b[38;5;241m.\u001b[39mgroup_by([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooks\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg(pivot_exprs)\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/lazyframe/frame.py:2053\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mStructFieldNotFoundError\u001b[0m: token\n\nThis error occurred with the following context stack:\n\t[1] 'select' failed\n\t[2] 'select' input failed to resolve\n\t[3] 'unique' input failed to resolve\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = exploded.select('token').unique()\n",
    "\n",
    "# Prepare pivot expressions\n",
    "pivot_exprs = [\n",
    "    pl.when(pl.col('token') == token)\n",
    "    .then(pl.col('frequency'))\n",
    "    .otherwise(None)\n",
    "    .sum()\n",
    "    .over(['authors', 'books'])\n",
    "    .alias(token)\n",
    "    for token in unique_tokens.get_column('token')\n",
    "]\n",
    "\n",
    "# Apply pivot expressions\n",
    "pivoted = exploded.group_by(['authors', 'books']).agg(pivot_exprs)\n",
    "\n",
    "return pivoted.select(\n",
    "    ['authors', 'books'] + \n",
    "    [pl.col(token).fill_null(0) for token in unique_tokens.collect().get_column('token')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = df.select(\n",
    "    pl.col('tokens')\n",
    "    .explode()\n",
    "    .value_counts(sort=True, normalize=True)\n",
    ").unnest('tokens').head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaError",
     "evalue": "invalid series dtype: expected `Struct`, got `str`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m token_freqs \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroup_by((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooks\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      2\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mexplode()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mvalue_counts(sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_freqs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Alternative that preserves all columns\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m token_freqs \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrequency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken_freqs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m token_freqs\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/dataframe/frame.py:9154\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   9008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_columns\u001b[39m(\n\u001b[1;32m   9009\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9010\u001b[0m     \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr],\n\u001b[1;32m   9011\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr,\n\u001b[1;32m   9012\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9013\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   9014\u001b[0m \u001b[38;5;124;03m    Add columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m   9015\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9152\u001b[0m \u001b[38;5;124;03m    └─────┴──────┴─────────────┘\u001b[39;00m\n\u001b[1;32m   9153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/lazyframe/frame.py:2053\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mSchemaError\u001b[0m: invalid series dtype: expected `Struct`, got `str`"
     ]
    }
   ],
   "source": [
    "token_freqs = df.group_by(('authors', 'books')).agg(\n",
    "    pl.col('tokens')\n",
    "    .list.explode()\n",
    "    .value_counts(sort=True, normalize=True)\n",
    "    .alias('token_freqs')\n",
    ")\n",
    "\n",
    "# Alternative that preserves all columns\n",
    "token_freqs = df.with_columns(\n",
    "    pl.col('tokens')\n",
    "    .list.eval(\n",
    "        pl.element()\n",
    "        .value_counts(sort=True, normalize=True)\n",
    "        .struct.rename_fields(('token', 'frequency'))\n",
    "    )\n",
    "    .list.eval(\n",
    "        pl.element().filter(\n",
    "            pl.element().struct.field('token').is_in(top_tokens.select('tokens'))\n",
    "        )\n",
    "    )\n",
    "    .alias('token_freqs')\n",
    ")\n",
    "\n",
    "token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "Series length 3 doesn't match the DataFrame height of 369571",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauthors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroup_by((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mcount()\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/dataframe/frame.py:8981\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   8881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[1;32m   8882\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[1;32m   8883\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8885\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[1;32m   8886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8979\u001b[0m \u001b[38;5;124;03m    └──────────────┘\u001b[39;00m\n\u001b[1;32m   8980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterstylometry/lib/python3.11/site-packages/polars/lazyframe/frame.py:2053\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mComputeError\u001b[0m: Series length 3 doesn't match the DataFrame height of 369571"
     ]
    }
   ],
   "source": [
    "token_counts = df.select([\n",
    "    pl.col('authors'),\n",
    "    pl.col('books'),\n",
    "    pl.col('tokens').list.explode().alias('token')\n",
    "]).group_by(('authors', 'books', 'token')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('token_counts', List(Struct({'token': String, 'count': UInt32})))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.select('token_counts').schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>authors</th><th>books</th><th>texts</th><th>tokens</th><th>token_count</th><th>token_counts</th><th>count</th></tr><tr><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>u32</td><td>struct[2]</td><td>struct[2]</td></tr></thead><tbody><tr><td>&quot;Hermann Melville&quot;</td><td>&quot;Moby Dick&quot;</td><td>&quot;MOBY-DICK;\n",
       "\n",
       "or, THE WHALE.\n",
       "\n",
       "By…</td><td>[&quot;MOBY&quot;, &quot;DICK&quot;, … &quot;orphan&quot;]</td><td>219454</td><td>{{&quot;the&quot;,13813},{&quot;of&quot;,6592}}</td><td>{&quot;of&quot;,6592}</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;The Adventures of Sherlock Hol…</td><td>&quot;HOLMES ***\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "The Adventures …</td><td>[&quot;HOLMES&quot;, &quot;The&quot;, … &quot;success&quot;]</td><td>105956</td><td>{{&quot;the&quot;,5263},{&quot;I&quot;,3038}}</td><td>{&quot;I&quot;,3038}</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;A Study in Scarlet&quot;</td><td>&quot;A STUDY IN SCARLET\n",
       "\n",
       "By A. Cona…</td><td>[&quot;A&quot;, &quot;STUDY&quot;, … &quot;arca&quot;]</td><td>44161</td><td>{{&quot;the&quot;,2326},{&quot;and&quot;,1321}}</td><td>{&quot;and&quot;,1321}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ authors      ┆ books       ┆ texts       ┆ tokens      ┆ token_count ┆ token_count ┆ count       │\n",
       "│ ---          ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ s           ┆ ---         │\n",
       "│ str          ┆ str         ┆ str         ┆ list[str]   ┆ u32         ┆ ---         ┆ struct[2]   │\n",
       "│              ┆             ┆             ┆             ┆             ┆ struct[2]   ┆             │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ Hermann      ┆ Moby Dick   ┆ MOBY-DICK;  ┆ [\"MOBY\",    ┆ 219454      ┆ {{\"the\",138 ┆ {\"of\",6592} │\n",
       "│ Melville     ┆             ┆             ┆ \"DICK\", …   ┆             ┆ 13},{\"of\",6 ┆             │\n",
       "│              ┆             ┆ or, THE     ┆ \"orphan\"]   ┆             ┆ 592}}       ┆             │\n",
       "│              ┆             ┆ WHALE.      ┆             ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆             ┆ By…         ┆             ┆             ┆             ┆             │\n",
       "│ Arthur Conan ┆ The         ┆ HOLMES ***  ┆ [\"HOLMES\",  ┆ 105956      ┆ {{\"the\",526 ┆ {\"I\",3038}  │\n",
       "│ Doyle        ┆ Adventures  ┆             ┆ \"The\", …    ┆             ┆ 3},{\"I\",303 ┆             │\n",
       "│              ┆ of Sherlock ┆             ┆ \"success\"]  ┆             ┆ 8}}         ┆             │\n",
       "│              ┆ Hol…        ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆             ┆ The         ┆             ┆             ┆             ┆             │\n",
       "│              ┆             ┆ Adventures  ┆             ┆             ┆             ┆             │\n",
       "│              ┆             ┆ …           ┆             ┆             ┆             ┆             │\n",
       "│ Arthur Conan ┆ A Study in  ┆ A STUDY IN  ┆ [\"A\",       ┆ 44161       ┆ {{\"the\",232 ┆ {\"and\",1321 │\n",
       "│ Doyle        ┆ Scarlet     ┆ SCARLET     ┆ \"STUDY\", …  ┆             ┆ 6},{\"and\",1 ┆ }           │\n",
       "│              ┆             ┆             ┆ \"arca\"]     ┆             ┆ 321}}       ┆             │\n",
       "│              ┆             ┆ By A. Cona… ┆             ┆             ┆             ┆             │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate word frequencies\n",
    "word_freqs = token_counts.with_columns([\n",
    "    pl.col('token_counts').struct.field('count')\n",
    "])\n",
    "\n",
    "word_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tokens</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;the&quot;</td><td>21402</td></tr><tr><td>&quot;of&quot;</td><td>10416</td></tr><tr><td>&quot;and&quot;</td><td>10214</td></tr><tr><td>&quot;to&quot;</td><td>8355</td></tr><tr><td>&quot;a&quot;</td><td>8097</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;man&quot;</td><td>965</td></tr><tr><td>&quot;been&quot;</td><td>955</td></tr><tr><td>&quot;up&quot;</td><td>940</td></tr><tr><td>&quot;no&quot;</td><td>927</td></tr><tr><td>&quot;when&quot;</td><td>919</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (50, 2)\n",
       "┌────────┬───────┐\n",
       "│ tokens ┆ count │\n",
       "│ ---    ┆ ---   │\n",
       "│ str    ┆ u32   │\n",
       "╞════════╪═══════╡\n",
       "│ the    ┆ 21402 │\n",
       "│ of     ┆ 10416 │\n",
       "│ and    ┆ 10214 │\n",
       "│ to     ┆ 8355  │\n",
       "│ a      ┆ 8097  │\n",
       "│ …      ┆ …     │\n",
       "│ man    ┆ 965   │\n",
       "│ been   ┆ 955   │\n",
       "│ up     ┆ 940   │\n",
       "│ no     ┆ 927   │\n",
       "│ when   ┆ 919   │\n",
       "└────────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top tokens over whole corpus - alternate implementation\n",
    "top_token_counts = df.select(\n",
    "    pl.col('tokens')\n",
    "    .explode()\n",
    "    .value_counts(sort=True)\n",
    "    .head(50)\n",
    "    .struct.field(['tokens', 'count'])\n",
    ")\n",
    "\n",
    "top_token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>authors</th><th>books</th><th>texts</th><th>tokens</th><th>token_count</th></tr><tr><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Hermann Melville&quot;</td><td>&quot;Moby Dick&quot;</td><td>&quot;MOBY-DICK;\n",
       "\n",
       "or, THE WHALE.\n",
       "\n",
       "By…</td><td>[&quot;MOBY&quot;, &quot;DICK&quot;, … &quot;orphan&quot;]</td><td>219454</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;The Adventures of Sherlock Hol…</td><td>&quot;HOLMES ***\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "The Adventures …</td><td>[&quot;HOLMES&quot;, &quot;The&quot;, … &quot;success&quot;]</td><td>105956</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;A Study in Scarlet&quot;</td><td>&quot;A STUDY IN SCARLET\n",
       "\n",
       "By A. Cona…</td><td>[&quot;A&quot;, &quot;STUDY&quot;, … &quot;arca&quot;]</td><td>44161</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌────────────────────┬─────────────────────┬────────────────────┬────────────────────┬─────────────┐\n",
       "│ authors            ┆ books               ┆ texts              ┆ tokens             ┆ token_count │\n",
       "│ ---                ┆ ---                 ┆ ---                ┆ ---                ┆ ---         │\n",
       "│ str                ┆ str                 ┆ str                ┆ list[str]          ┆ u32         │\n",
       "╞════════════════════╪═════════════════════╪════════════════════╪════════════════════╪═════════════╡\n",
       "│ Hermann Melville   ┆ Moby Dick           ┆ MOBY-DICK;         ┆ [\"MOBY\", \"DICK\", … ┆ 219454      │\n",
       "│                    ┆                     ┆                    ┆ \"orphan\"]          ┆             │\n",
       "│                    ┆                     ┆ or, THE WHALE.     ┆                    ┆             │\n",
       "│                    ┆                     ┆                    ┆                    ┆             │\n",
       "│                    ┆                     ┆ By…                ┆                    ┆             │\n",
       "│ Arthur Conan Doyle ┆ The Adventures of   ┆ HOLMES ***         ┆ [\"HOLMES\", \"The\",  ┆ 105956      │\n",
       "│                    ┆ Sherlock Hol…       ┆                    ┆ … \"success\"]       ┆             │\n",
       "│                    ┆                     ┆                    ┆                    ┆             │\n",
       "│                    ┆                     ┆                    ┆                    ┆             │\n",
       "│                    ┆                     ┆                    ┆                    ┆             │\n",
       "│                    ┆                     ┆ The Adventures …   ┆                    ┆             │\n",
       "│ Arthur Conan Doyle ┆ A Study in Scarlet  ┆ A STUDY IN SCARLET ┆ [\"A\", \"STUDY\", …   ┆ 44161       │\n",
       "│                    ┆                     ┆                    ┆ \"arca\"]            ┆             │\n",
       "│                    ┆                     ┆ By A. Cona…        ┆                    ┆             │\n",
       "└────────────────────┴─────────────────────┴────────────────────┴────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get length of each book\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens')\n",
    "    .list.len()\n",
    "    .alias('token_count')\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>authors</th><th>books</th><th>texts</th><th>tokens</th><th>top_token_counts</th></tr><tr><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>struct[50]</td></tr></thead><tbody><tr><td>&quot;Hermann Melville&quot;</td><td>&quot;Moby Dick&quot;</td><td>&quot;MOBY-DICK;\n",
       "\n",
       "or, THE WHALE.\n",
       "\n",
       "By…</td><td>[&quot;MOBY&quot;, &quot;DICK&quot;, … &quot;orphan&quot;]</td><td>{{&quot;of&quot;,6592},{&quot;as&quot;,1621},{&quot;there&quot;,716},{&quot;me&quot;,627},{&quot;up&quot;,507},{&quot;have&quot;,760},{&quot;he&quot;,1662},{&quot;one&quot;,893},{&quot;but&quot;,1113},{&quot;my&quot;,564},{&quot;so&quot;,918},{&quot;is&quot;,1698},{&quot;to&quot;,4561},{&quot;for&quot;,1421},{&quot;all&quot;,1466},{&quot;by&quot;,1144},{&quot;the&quot;,13813},{&quot;you&quot;,841},{&quot;no&quot;,486},{&quot;was&quot;,1634},{&quot;man&quot;,508},{&quot;from&quot;,1061},{&quot;a&quot;,4591},{&quot;on&quot;,1016},{&quot;this&quot;,1281},{&quot;when&quot;,554},{&quot;out&quot;,529},{&quot;an&quot;,582},{&quot;in&quot;,3942},{&quot;be&quot;,1030},{&quot;or&quot;,703},{&quot;not&quot;,1105},{&quot;that&quot;,2981},{&quot;are&quot;,587},{&quot;said&quot;,304},{&quot;at&quot;,1236},{&quot;had&quot;,767},{&quot;we&quot;,413},{&quot;were&quot;,679},{&quot;his&quot;,2472},{&quot;been&quot;,415},{&quot;him&quot;,1060},{&quot;it&quot;,2210},{&quot;upon&quot;,540},{&quot;with&quot;,1663},{&quot;I&quot;,2120},{&quot;and&quot;,6075},{&quot;s&quot;,1800},{&quot;The&quot;,702},{&quot;which&quot;,642}}</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;The Adventures of Sherlock Hol…</td><td>&quot;HOLMES ***\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "The Adventures …</td><td>[&quot;HOLMES&quot;, &quot;The&quot;, … &quot;success&quot;]</td><td>{{&quot;to&quot;,2715},{&quot;for&quot;,695},{&quot;are&quot;,329},{&quot;me&quot;,635},{&quot;the&quot;,5263},{&quot;by&quot;,322},{&quot;The&quot;,341},{&quot;his&quot;,1103},{&quot;that&quot;,1651},{&quot;which&quot;,763},{&quot;one&quot;,338},{&quot;when&quot;,265},{&quot;upon&quot;,463},{&quot;you&quot;,1231},{&quot;was&quot;,1392},{&quot;but&quot;,469},{&quot;on&quot;,336},{&quot;we&quot;,412},{&quot;so&quot;,414},{&quot;be&quot;,624},{&quot;no&quot;,299},{&quot;up&quot;,300},{&quot;there&quot;,343},{&quot;in&quot;,1692},{&quot;man&quot;,302},{&quot;my&quot;,907},{&quot;a&quot;,2538},{&quot;I&quot;,3038},{&quot;been&quot;,393},{&quot;not&quot;,612},{&quot;at&quot;,729},{&quot;with&quot;,803},{&quot;and&quot;,2818},{&quot;of&quot;,2625},{&quot;as&quot;,770},{&quot;he&quot;,1165},{&quot;had&quot;,822},{&quot;this&quot;,405},{&quot;from&quot;,477},{&quot;it&quot;,1290},{&quot;have&quot;,904},{&quot;s&quot;,365},{&quot;is&quot;,1106},{&quot;all&quot;,370},{&quot;or&quot;,194},{&quot;were&quot;,345},{&quot;him&quot;,434},{&quot;out&quot;,319},{&quot;an&quot;,323},{&quot;said&quot;,486}}</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;A Study in Scarlet&quot;</td><td>&quot;A STUDY IN SCARLET\n",
       "\n",
       "By A. Cona…</td><td>[&quot;A&quot;, &quot;STUDY&quot;, … &quot;arca&quot;]</td><td>{{&quot;been&quot;,147},{&quot;not&quot;,170},{&quot;be&quot;,248},{&quot;as&quot;,299},{&quot;s&quot;,190},{&quot;me&quot;,212},{&quot;an&quot;,128},{&quot;are&quot;,132},{&quot;up&quot;,133},{&quot;at&quot;,289},{&quot;which&quot;,315},{&quot;or&quot;,112},{&quot;his&quot;,613},{&quot;out&quot;,120},{&quot;this&quot;,178},{&quot;that&quot;,619},{&quot;a&quot;,968},{&quot;when&quot;,100},{&quot;with&quot;,313},{&quot;from&quot;,173},{&quot;on&quot;,190},{&quot;had&quot;,470},{&quot;have&quot;,276},{&quot;of&quot;,1199},{&quot;we&quot;,142},{&quot;and&quot;,1321},{&quot;it&quot;,453},{&quot;one&quot;,150},{&quot;you&quot;,367},{&quot;was&quot;,647},{&quot;to&quot;,1079},{&quot;upon&quot;,195},{&quot;all&quot;,173},{&quot;in&quot;,673},{&quot;but&quot;,172},{&quot;man&quot;,155},{&quot;is&quot;,288},{&quot;him&quot;,271},{&quot;no&quot;,142},{&quot;The&quot;,190},{&quot;there&quot;,160},{&quot;he&quot;,630},{&quot;my&quot;,273},{&quot;so&quot;,139},{&quot;said&quot;,207},{&quot;I&quot;,943},{&quot;were&quot;,169},{&quot;by&quot;,152},{&quot;the&quot;,2326},{&quot;for&quot;,303}}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌───────────────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│ authors           ┆ books             ┆ texts             ┆ tokens            ┆ top_token_counts │\n",
       "│ ---               ┆ ---               ┆ ---               ┆ ---               ┆ ---              │\n",
       "│ str               ┆ str               ┆ str               ┆ list[str]         ┆ struct[50]       │\n",
       "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════════════╡\n",
       "│ Hermann Melville  ┆ Moby Dick         ┆ MOBY-DICK;        ┆ [\"MOBY\", \"DICK\",  ┆ {{\"of\",6592},{\"a │\n",
       "│                   ┆                   ┆                   ┆ … \"orphan\"]       ┆ s\",1621},{\"the…  │\n",
       "│                   ┆                   ┆ or, THE WHALE.    ┆                   ┆                  │\n",
       "│                   ┆                   ┆                   ┆                   ┆                  │\n",
       "│                   ┆                   ┆ By…               ┆                   ┆                  │\n",
       "│ Arthur Conan      ┆ The Adventures of ┆ HOLMES ***        ┆ [\"HOLMES\", \"The\", ┆ {{\"to\",2715},{\"f │\n",
       "│ Doyle             ┆ Sherlock Hol…     ┆                   ┆ … \"success\"]      ┆ or\",695},{\"are…  │\n",
       "│                   ┆                   ┆                   ┆                   ┆                  │\n",
       "│                   ┆                   ┆                   ┆                   ┆                  │\n",
       "│                   ┆                   ┆                   ┆                   ┆                  │\n",
       "│                   ┆                   ┆ The Adventures …  ┆                   ┆                  │\n",
       "│ Arthur Conan      ┆ A Study in        ┆ A STUDY IN        ┆ [\"A\", \"STUDY\", …  ┆ {{\"been\",147},{\" │\n",
       "│ Doyle             ┆ Scarlet           ┆ SCARLET           ┆ \"arca\"]           ┆ not\",170},{\"be…  │\n",
       "│                   ┆                   ┆                   ┆                   ┆                  │\n",
       "│                   ┆                   ┆ By A. Cona…       ┆                   ┆                  │\n",
       "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get token counts of top tokens for each book\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens')\n",
    "    .list.eval(\n",
    "        pl.element().filter(\n",
    "            pl.element().is_in(top_token_counts.select('tokens'))\n",
    "        )\n",
    "        .value_counts()\n",
    "    )\n",
    "    .list.to_struct()\n",
    "    .alias('top_token_counts')\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>authors</th><th>top_token_counts</th></tr><tr><td>str</td><td>struct[50]</td></tr></thead><tbody><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>{{&quot;out&quot;,439},{&quot;upon&quot;,658},{&quot;so&quot;,553},{&quot;me&quot;,847},{&quot;been&quot;,540},{&quot;from&quot;,650},{&quot;we&quot;,554},{&quot;are&quot;,461},{&quot;have&quot;,1180},{&quot;with&quot;,1116},{&quot;were&quot;,514},{&quot;by&quot;,474},{&quot;had&quot;,1292},{&quot;that&quot;,2270},{&quot;no&quot;,441},{&quot;when&quot;,365},{&quot;is&quot;,1394},{&quot;in&quot;,2365},{&quot;he&quot;,1795},{&quot;you&quot;,1598},{&quot;as&quot;,1069},{&quot;this&quot;,583},{&quot;up&quot;,433},{&quot;I&quot;,3981},{&quot;for&quot;,998},{&quot;and&quot;,4139},{&quot;him&quot;,705},{&quot;his&quot;,1716},{&quot;all&quot;,543},{&quot;was&quot;,2039},{&quot;there&quot;,503},{&quot;on&quot;,526},{&quot;but&quot;,641},{&quot;said&quot;,693},{&quot;at&quot;,1018},{&quot;the&quot;,7589},{&quot;be&quot;,872},{&quot;which&quot;,1078},{&quot;to&quot;,3794},{&quot;or&quot;,306},{&quot;an&quot;,451},{&quot;my&quot;,1180},{&quot;one&quot;,488},{&quot;a&quot;,3506},{&quot;it&quot;,1743},{&quot;The&quot;,531},{&quot;not&quot;,782},{&quot;of&quot;,3824},{&quot;man&quot;,457},{&quot;s&quot;,555}}</td></tr><tr><td>&quot;Hermann Melville&quot;</td><td>{{&quot;s&quot;,1800},{&quot;from&quot;,1061},{&quot;the&quot;,13813},{&quot;all&quot;,1466},{&quot;out&quot;,529},{&quot;me&quot;,627},{&quot;my&quot;,564},{&quot;and&quot;,6075},{&quot;to&quot;,4561},{&quot;by&quot;,1144},{&quot;had&quot;,767},{&quot;with&quot;,1663},{&quot;him&quot;,1060},{&quot;be&quot;,1030},{&quot;there&quot;,716},{&quot;when&quot;,554},{&quot;his&quot;,2472},{&quot;but&quot;,1113},{&quot;on&quot;,1016},{&quot;this&quot;,1281},{&quot;The&quot;,702},{&quot;a&quot;,4591},{&quot;as&quot;,1621},{&quot;was&quot;,1634},{&quot;that&quot;,2981},{&quot;have&quot;,760},{&quot;no&quot;,486},{&quot;for&quot;,1421},{&quot;it&quot;,2210},{&quot;is&quot;,1698},{&quot;one&quot;,893},{&quot;of&quot;,6592},{&quot;in&quot;,3942},{&quot;you&quot;,841},{&quot;not&quot;,1105},{&quot;been&quot;,415},{&quot;upon&quot;,540},{&quot;said&quot;,304},{&quot;are&quot;,587},{&quot;which&quot;,642},{&quot;so&quot;,918},{&quot;we&quot;,413},{&quot;at&quot;,1236},{&quot;up&quot;,507},{&quot;or&quot;,703},{&quot;were&quot;,679},{&quot;an&quot;,582},{&quot;I&quot;,2120},{&quot;he&quot;,1662},{&quot;man&quot;,508}}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────────────────┬─────────────────────────────────┐\n",
       "│ authors            ┆ top_token_counts                │\n",
       "│ ---                ┆ ---                             │\n",
       "│ str                ┆ struct[50]                      │\n",
       "╞════════════════════╪═════════════════════════════════╡\n",
       "│ Arthur Conan Doyle ┆ {{\"out\",439},{\"upon\",658},{\"so… │\n",
       "│ Hermann Melville   ┆ {{\"s\",1800},{\"from\",1061},{\"th… │\n",
       "└────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get token counts of top tokens for each author - SEE IF THERE IS A WAY TO MERGE TOP_TOKEN_COUNTS STRUCTS FOR FASTER IMPLEMENTATION\n",
    "df.group_by('authors').agg(\n",
    "    pl.col('tokens')\n",
    "    .list.eval(\n",
    "        pl.element().filter(\n",
    "            pl.element().is_in(top_token_counts.select('tokens'))\n",
    "        )\n",
    "    )\n",
    "    .explode()\n",
    "    .value_counts()\n",
    "    .alias('top_token_counts')\n",
    ").with_columns(\n",
    "    pl.col('top_token_counts')\n",
    "    .list.to_struct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>authors</th><th>books</th><th>top_token_counts</th></tr><tr><td>str</td><td>str</td><td>struct[50]</td></tr></thead><tbody><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;The Adventures of Sherlock Hol…</td><td>{{&quot;there&quot;,343},{&quot;have&quot;,904},{&quot;his&quot;,1103},{&quot;was&quot;,1392},{&quot;that&quot;,1651},{&quot;up&quot;,300},{&quot;man&quot;,302},{&quot;been&quot;,393},{&quot;but&quot;,469},{&quot;at&quot;,729},{&quot;are&quot;,329},{&quot;the&quot;,5263},{&quot;one&quot;,338},{&quot;as&quot;,770},{&quot;a&quot;,2538},{&quot;which&quot;,763},{&quot;him&quot;,434},{&quot;out&quot;,319},{&quot;on&quot;,336},{&quot;you&quot;,1231},{&quot;is&quot;,1106},{&quot;from&quot;,477},{&quot;The&quot;,341},{&quot;and&quot;,2818},{&quot;of&quot;,2625},{&quot;in&quot;,1692},{&quot;with&quot;,803},{&quot;said&quot;,486},{&quot;no&quot;,299},{&quot;me&quot;,635},{&quot;he&quot;,1165},{&quot;we&quot;,412},{&quot;this&quot;,405},{&quot;it&quot;,1290},{&quot;upon&quot;,463},{&quot;I&quot;,3038},{&quot;or&quot;,194},{&quot;s&quot;,365},{&quot;by&quot;,322},{&quot;not&quot;,612},{&quot;for&quot;,695},{&quot;were&quot;,345},{&quot;all&quot;,370},{&quot;my&quot;,907},{&quot;to&quot;,2715},{&quot;when&quot;,265},{&quot;so&quot;,414},{&quot;an&quot;,323},{&quot;had&quot;,822},{&quot;be&quot;,624}}</td></tr><tr><td>&quot;Arthur Conan Doyle&quot;</td><td>&quot;A Study in Scarlet&quot;</td><td>{{&quot;in&quot;,673},{&quot;by&quot;,152},{&quot;him&quot;,271},{&quot;from&quot;,173},{&quot;on&quot;,190},{&quot;The&quot;,190},{&quot;but&quot;,172},{&quot;me&quot;,212},{&quot;the&quot;,2326},{&quot;been&quot;,147},{&quot;or&quot;,112},{&quot;his&quot;,613},{&quot;he&quot;,630},{&quot;my&quot;,273},{&quot;it&quot;,453},{&quot;not&quot;,170},{&quot;to&quot;,1079},{&quot;we&quot;,142},{&quot;that&quot;,619},{&quot;s&quot;,190},{&quot;as&quot;,299},{&quot;and&quot;,1321},{&quot;with&quot;,313},{&quot;at&quot;,289},{&quot;there&quot;,160},{&quot;a&quot;,968},{&quot;man&quot;,155},{&quot;all&quot;,173},{&quot;I&quot;,943},{&quot;for&quot;,303},{&quot;upon&quot;,195},{&quot;have&quot;,276},{&quot;an&quot;,128},{&quot;up&quot;,133},{&quot;this&quot;,178},{&quot;of&quot;,1199},{&quot;so&quot;,139},{&quot;was&quot;,647},{&quot;had&quot;,470},{&quot;were&quot;,169},{&quot;one&quot;,150},{&quot;out&quot;,120},{&quot;when&quot;,100},{&quot;is&quot;,288},{&quot;said&quot;,207},{&quot;you&quot;,367},{&quot;no&quot;,142},{&quot;be&quot;,248},{&quot;which&quot;,315},{&quot;are&quot;,132}}</td></tr><tr><td>&quot;Hermann Melville&quot;</td><td>&quot;Moby Dick&quot;</td><td>{{&quot;at&quot;,1236},{&quot;was&quot;,1634},{&quot;this&quot;,1281},{&quot;is&quot;,1698},{&quot;I&quot;,2120},{&quot;which&quot;,642},{&quot;of&quot;,6592},{&quot;as&quot;,1621},{&quot;one&quot;,893},{&quot;from&quot;,1061},{&quot;The&quot;,702},{&quot;him&quot;,1060},{&quot;he&quot;,1662},{&quot;said&quot;,304},{&quot;no&quot;,486},{&quot;there&quot;,716},{&quot;we&quot;,413},{&quot;upon&quot;,540},{&quot;on&quot;,1016},{&quot;were&quot;,679},{&quot;but&quot;,1113},{&quot;his&quot;,2472},{&quot;up&quot;,507},{&quot;man&quot;,508},{&quot;you&quot;,841},{&quot;have&quot;,760},{&quot;or&quot;,703},{&quot;the&quot;,13813},{&quot;be&quot;,1030},{&quot;that&quot;,2981},{&quot;for&quot;,1421},{&quot;a&quot;,4591},{&quot;s&quot;,1800},{&quot;not&quot;,1105},{&quot;to&quot;,4561},{&quot;out&quot;,529},{&quot;it&quot;,2210},{&quot;been&quot;,415},{&quot;me&quot;,627},{&quot;my&quot;,564},{&quot;when&quot;,554},{&quot;in&quot;,3942},{&quot;are&quot;,587},{&quot;with&quot;,1663},{&quot;so&quot;,918},{&quot;an&quot;,582},{&quot;all&quot;,1466},{&quot;had&quot;,767},{&quot;by&quot;,1144},{&quot;and&quot;,6075}}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ authors            ┆ books                           ┆ top_token_counts                │\n",
       "│ ---                ┆ ---                             ┆ ---                             │\n",
       "│ str                ┆ str                             ┆ struct[50]                      │\n",
       "╞════════════════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ Arthur Conan Doyle ┆ The Adventures of Sherlock Hol… ┆ {{\"there\",343},{\"have\",904},{\"… │\n",
       "│ Arthur Conan Doyle ┆ A Study in Scarlet              ┆ {{\"in\",673},{\"by\",152},{\"him\",… │\n",
       "│ Hermann Melville   ┆ Moby Dick                       ┆ {{\"at\",1236},{\"was\",1634},{\"th… │\n",
       "└────────────────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get token counts of top tokens for each author-book combination\n",
    "df.group_by(['authors', 'books']).agg(\n",
    "    pl.col('tokens')\n",
    "    .list.eval(\n",
    "        pl.element().filter(\n",
    "            pl.element().is_in(top_token_counts.select('tokens'))\n",
    "        )\n",
    "    )\n",
    "    .explode()\n",
    "    .value_counts()\n",
    "    .alias('top_token_counts')\n",
    ").with_columns(\n",
    "    pl.col('top_token_counts')\n",
    "    .list.to_struct()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasterstylometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
